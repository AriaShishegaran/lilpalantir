Citation Query Engine[](#module-llama_index.query_engine.citation_query_engine "Permalink to this heading")
============================================================================================================

*class* llama\_index.query\_engine.citation\_query\_engine.CitationQueryEngine(*retriever: [BaseRetriever](../retrievers.html#llama_index.indices.base_retriever.BaseRetriever "llama_index.indices.base_retriever.BaseRetriever")*, *response\_synthesizer: Optional[[BaseSynthesizer](../response_synthesizer.html#llama_index.response_synthesizers.BaseSynthesizer "llama_index.response_synthesizers.base.BaseSynthesizer")] = None*, *citation\_chunk\_size: int = 512*, *citation\_chunk\_overlap: int = 20*, *text\_splitter: Optional[TextSplitter] = None*, *node\_postprocessors: Optional[List[BaseNodePostprocessor]] = None*, *callback\_manager: Optional[[CallbackManager](../../callbacks.html#llama_index.callbacks.CallbackManager "llama_index.callbacks.base.CallbackManager")] = None*, *metadata\_mode: [MetadataMode](../../node.html#llama_index.schema.MetadataMode "llama_index.schema.MetadataMode") = MetadataMode.NONE*)[](#llama_index.query_engine.citation_query_engine.CitationQueryEngine "Permalink to this definition")Citation query engine.

Parameters* **retriever** ([*BaseRetriever*](../retrievers.html#llama_index.indices.base_retriever.BaseRetriever "llama_index.indices.base_retriever.BaseRetriever")) – A retriever object.
* **response\_synthesizer** (*Optional**[*[*BaseSynthesizer*](../response_synthesizer.html#llama_index.response_synthesizers.BaseSynthesizer "llama_index.response_synthesizers.BaseSynthesizer")*]*) – A BaseSynthesizer object.
* **citation\_chunk\_size** (*int*) – Size of citation chunks, default=512. Useful for controllinggranularity of sources.
* **citation\_chunk\_overlap** (*int*) – Overlap of citation nodes, default=20.
* **text\_splitter** (*Optional**[**TextSplitterType**]*) – A text splitter for creating citation source nodes. Default isa SentenceSplitter.
* **callback\_manager** (*Optional**[*[*CallbackManager*](../../callbacks.html#llama_index.callbacks.CallbackManager "llama_index.callbacks.CallbackManager")*]*) – A callback manager.
* **metadata\_mode** ([*MetadataMode*](../../node.html#llama_index.schema.MetadataMode "llama_index.schema.MetadataMode")) – A MetadataMode object that controls howmetadata is included in the citation prompt.
*classmethod* from\_args(*index: ~llama\_index.indices.base.BaseIndex, response\_synthesizer: ~typing.Optional[~llama\_index.response\_synthesizers.base.BaseSynthesizer] = None, citation\_chunk\_size: int = 512, citation\_chunk\_overlap: int = 20, text\_splitter: ~typing.Optional[~llama\_index.text\_splitter.types.TextSplitter] = None, citation\_qa\_template: ~llama\_index.prompts.base.BasePromptTemplate = PromptTemplate(metadata={'prompt\_type': <PromptType.CUSTOM: 'custom'>}, template\_vars=['context\_str', 'query\_str'], kwargs={}, output\_parser=None, template\_var\_mappings=None, function\_mappings=None, template="Please provide an answer based solely on the provided sources. When referencing information from a source, cite the appropriate source(s) using their corresponding numbers. Every answer should include at least one source citation. Only cite a source when you are explicitly referencing it. If none of the sources are helpful, you should indicate that. For example:\nSource 1:\nThe sky is red in the evening and blue in the morning.\nSource 2:\nWater is wet when the sky is red.\nQuery: When is water wet?\nAnswer: Water will be wet when the sky is red [2], which occurs in the evening [1].\nNow it's your turn. Below are several numbered sources of information:\n------\n{context\_str}\n------\nQuery: {query\_str}\nAnswer: "), citation\_refine\_template: ~llama\_index.prompts.base.BasePromptTemplate = PromptTemplate(metadata={'prompt\_type': <PromptType.CUSTOM: 'custom'>}, template\_vars=['existing\_answer', 'context\_msg', 'query\_str'], kwargs={}, output\_parser=None, template\_var\_mappings=None, function\_mappings=None, template="Please provide an answer based solely on the provided sources. When referencing information from a source, cite the appropriate source(s) using their corresponding numbers. Every answer should include at least one source citation. Only cite a source when you are explicitly referencing it. If none of the sources are helpful, you should indicate that. For example:\nSource 1:\nThe sky is red in the evening and blue in the morning.\nSource 2:\nWater is wet when the sky is red.\nQuery: When is water wet?\nAnswer: Water will be wet when the sky is red [2], which occurs in the evening [1].\nNow it's your turn. We have provided an existing answer: {existing\_answer}Below are several numbered sources of information. Use them to refine the existing answer. If the provided sources are not helpful, you will repeat the existing answer.\nBegin refining!\n------\n{context\_msg}\n------\nQuery: {query\_str}\nAnswer: "), retriever: ~typing.Optional[~llama\_index.indices.base\_retriever.BaseRetriever] = None, node\_postprocessors: ~typing.Optional[~typing.List[~llama\_index.indices.postprocessor.types.BaseNodePostprocessor]] = None, response\_mode: ~llama\_index.response\_synthesizers.type.ResponseMode = ResponseMode.COMPACT, use\_async: bool = False, streaming: bool = False, metadata\_mode: ~llama\_index.schema.MetadataMode = MetadataMode.NONE, \*\*kwargs: ~typing.Any*) → [CitationQueryEngine](#llama_index.query_engine.citation_query_engine.CitationQueryEngine "llama_index.query_engine.citation_query_engine.CitationQueryEngine")[](#llama_index.query_engine.citation_query_engine.CitationQueryEngine.from_args "Permalink to this definition")Initialize a CitationQueryEngine object.”.

Parameters* **index** – (BastGPTIndex): index to use for querying
* **citation\_chunk\_size** (*int*) – Size of citation chunks, default=512. Useful for controllinggranularity of sources.
* **citation\_chunk\_overlap** (*int*) – Overlap of citation nodes, default=20.
* **text\_splitter** (*Optional**[**TextSplitter**]*) – A text splitter for creating citation source nodes. Default isa SentenceSplitter.
* **citation\_qa\_template** ([*BasePromptTemplate*](../../prompts.html#llama_index.prompts.base.BasePromptTemplate "llama_index.prompts.base.BasePromptTemplate")) – Template for initial citation QA
* **citation\_refine\_template** ([*BasePromptTemplate*](../../prompts.html#llama_index.prompts.base.BasePromptTemplate "llama_index.prompts.base.BasePromptTemplate")) – Template for citation refinement.
* **retriever** ([*BaseRetriever*](../retrievers.html#llama_index.indices.base_retriever.BaseRetriever "llama_index.indices.base_retriever.BaseRetriever")) – A retriever object.
* **service\_context** (*Optional**[*[*ServiceContext*](../../service_context.html#llama_index.indices.service_context.ServiceContext "llama_index.indices.service_context.ServiceContext")*]*) – A ServiceContext object.
* **node\_postprocessors** (*Optional**[**List**[**BaseNodePostprocessor**]**]*) – A list ofnode postprocessors.
* **verbose** (*bool*) – Whether to print out debug info.
* **response\_mode** ([*ResponseMode*](../response_synthesizer.html#llama_index.response_synthesizers.ResponseMode "llama_index.response_synthesizers.ResponseMode")) – A ResponseMode object.
* **use\_async** (*bool*) – Whether to use async.
* **streaming** (*bool*) – Whether to use streaming.
* **optimizer** (*Optional**[**BaseTokenUsageOptimizer**]*) – A BaseTokenUsageOptimizerobject.
get\_prompts() → Dict[str, [BasePromptTemplate](../../prompts.html#llama_index.prompts.base.BasePromptTemplate "llama_index.prompts.base.BasePromptTemplate")][](#llama_index.query_engine.citation_query_engine.CitationQueryEngine.get_prompts "Permalink to this definition")Get a prompt.

*property* retriever*: [BaseRetriever](../retrievers.html#llama_index.indices.base_retriever.BaseRetriever "llama_index.indices.base_retriever.BaseRetriever")*[](#llama_index.query_engine.citation_query_engine.CitationQueryEngine.retriever "Permalink to this definition")Get the retriever object.

update\_prompts(*prompts\_dict: Dict[str, [BasePromptTemplate](../../prompts.html#llama_index.prompts.base.BasePromptTemplate "llama_index.prompts.base.BasePromptTemplate")]*) → None[](#llama_index.query_engine.citation_query_engine.CitationQueryEngine.update_prompts "Permalink to this definition")Update prompts.

Other prompts will remain in place.

